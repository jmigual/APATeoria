# Meeting 2019-11-02

In this meeting we discussed the paper related to schedulability analysis of **gang tasks** where all the number of cores assigned to the task are the number of available cores at that moment, as long as the task is asking for them.

## Remarks in some definitions:

- Availability of $k$ cores in system state $v$
  - Possible available cores at time $A_k^{\min}(v)$
  - Certainly available cores at time $A_k^{\max}(v)$
$$
A_k(v) = [A_k^{\min}(v), A_k^{\max}(v)]
$$
- Number of cores on which a job $J_i$ may be executed in parallel
  - Minimum: $s_i^{\min}$
  - Maximum: $s_i^max$
$$
s_i^{\min} \le p \le s_i^{\max}
$$
- Release time of a job $J_i$:
  - Minimum: $r_i^{\min}$
  - Maximum: $r_i^{\max}$
- Job execution time depends on number of cores:
$$
c_i(p) \in [c_i^{\min}(p), c_i^{\max}(p)]
$$

- Set of jobs $\mathcal{J}$
- Jobs that have been scheduled: $\mathcal{J}^v$
- Jobs that have not been yet scheduled: $\mathcal{J} \setminus \mathcal{J}^v$
- We are using a global Job-Level Fixed Priority (JLFP) scheduling algorithm. It has the following rules
  1. A job $J_i$ is eligible to be scheduled at time $t$ if and only if it is released at or before $t$ and there are at least $s_i^{\min}$ cores available at time $t$
  2. At each scheduling decision, the highest priority job eligible at time $t$ is chosen to be dispatched
  3. The dispatched job always executes on the minimum between $s_i^{\max}$ and the number of cores available at the time at which it was dispatched
  4. The number of cores allocated to a job may not change during its execution
  5. **No core may remain idle as long as there are eligible jobs to be dispatched**.

## Analysis

- **Earliest Start Time**: Earliest time at which a task _could_ be scheduled with $p$ cores
$$
\tag{1}
EST_i = \max\{r_i^{\min},A_p^{\min}\}
$$

- **Latest Start Time**: Latest time at which job $J_i$ could be the next job dispatched in the current system state. We define it as the minimum time between two conditions:

  - We have to release the job always before a job with higher priority is certainly released and we also have the minimum number of cores available:

$$
\tag{4}
t_{high} = \min_{J_j\in hp_i \cap \{\mathcal{J}\setminus\mathcal{J}^v\}}^\infty \{\max\{r_j^{\max},A_{s_j^{\min}}^{\max}\}\}
$$

- We have to release the job at most at the time at which another job with lower priority (or the job) is going to be certainly released because a work-conserving scheduler (the one we have) is going to put that job before $J_i$ equation
  
$$
\tag{3}
  t_{wc} = \min_{J_j\in \{\mathcal{J} \setminus\mathcal{J}^v\}}
$$

$$
\tag{2}
LST_i = \min\{t_{wc}, t_{high} -1\}
$$
- **Eligibility**: A job $J_i$ is eligible to be dispatched next on $p$ cores (with $s_i^{\min} \le p \le s_i^{\max}$) if
$$
\tag{5}
EST_i^p \le LST^p \land EST_i^p < A_{p+1}^{\max}
$$
- **Finish Time**:

  - Earliest Finishing Time of job $J_i$ on $p$ cores is given by:
$$
\tag{6}
  EFT_i^p = EST_i^p + c_i^{\min}(p)
$$
  - Latest Finishing Time of job $J_i$ on $p$ cores is given by:
$$
LFT_i^p = \begin{cases}
  LST_i + c_i^{\max}(p) & \text{if } LST_i < A_{p+1}^{\max} \\
  A_{p+1}^{\max} + c_i^{\max}(p) - 1 & \text{otherwise}
  \end{cases}
$$
- **New state**: If job $J_i$ is eligible to execute on $p$ cores in system state $v$, then create a new state $v'$ in the schedule abstraction graph and construct the availability intervals $A_k(v')$ according to Algorithm 1:

  - Possible cores availability times (PA):
$$
\tag{8}
  PA = \Big\{ \max\{A_k^{\min}(v), EST_i^p\} | p < k \le m \Big\} \cup \Big\{p \times \{EFT_i^p\}\Big\}
$$
- Certainly available times (CA):
$$
\tag{9}
  CA = \Big\{ \max\{A_k^{\max}(v),EST_i^p\} | p < k \le m\Big\} \cup \Big\{p \times \{LFT_i^p\}\Big\}
$$


```{.python caption="Algorithm 1"}
PA = computePA() # Use equation 8
CA = computeCA() # Use equation 9
PA = reversed(sorted(PA))
CA = reversed(sorted(CA))
A = zip(PA, CA)
```

Merge all new states resulting from dispatching $J_i$ on any number of cores in system state $v$.

## Important for next meeting

- Analyse other good gang malleable algorithms
- Properly understand the analysis and make it mine
- Read the stat of the art in gang scheduling
- Check cloud computing solutions in gang scheduling
  - They could have different concerts like fairness instead of Best Case Response Time or Mean Case Response Time
- For next meeting I should have an agenda, not necessarily known but I should be the one leading the meeting.

