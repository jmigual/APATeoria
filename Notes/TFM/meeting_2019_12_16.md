
# Meeting 2019-12-16

## New formulation

### Simple formulation

Only change the Latest Start Time ($LST_i$) in order to have the number of required cores ($LST_I^p$)
$$
\begin{aligned}
LST_i^p &= \min\{t_{wc}, t_{high}^p(J_i) - 1\} \\
t_{wc} &= \min_{J_j \in \mathcal{R}^v}\{\max\{R_j^{\max}, A_{s_j^{\min}}^{\max}\}\} \\
t_{high}^p(J_i) &= \min_{J_j \in \{hp_i\cap \mathcal{R}^v\}}^{\infty}\Big\{\max\Big\{t_{h}^p(J_i, J_j), 
\max_0 \{LFT^*_y(v) | J_y \in \mathcal{P}(J_j) \setminus \mathcal{P}(J_i)\}\Big\}\Big\} \\
t_{h}^p(J_i, J_j) &= \begin{cases}
r_j^{\max} & \text{ if } s_j^{\min} \le p \\
\max\{r_j^{\max}, A_{s_j^{\min}}^{\max}\} & \text{ otherwise}
\end{cases}
\end{aligned}
$$


### Advanced one

Change the Latest Start Time ($LST_i$) in order to have the number of required cores ($LST_i^p$)
$$
\begin{aligned}
LST_i^p &= \min\{t_{wc}, t_{high}^p(J_i) - 1, t^p_{available}(J_i)\} \\
t_{wc} &= \min_{J_j \in \mathcal{R}^v}\{\max\{R_j^{\max}, A_{s_j^{\min}}^{\max}\}\} \\
t_{high}^p(J_i) &= \min_{J_j \in \{hp_i\cap \mathcal{R}^v\}}^{\infty}\Big\{\max\Big\{t_{h}^p(J_i, J_j),
\max_0 \{LFT^*_y(v) | J_y \in \mathcal{P}(J_j) \setminus \mathcal{P}(J_i)\}\Big\}\Big\} \\
t_{h}^p(J_i, J_j) &= \begin{cases}
r_j^{\max} & \text{ if } s_j^{\min} \le p \\
\max\{r_j^{\max}, A_{s_j^{\min}}^{\max}\} & \text{ otherwise}
\end{cases} \\
t_{available}^p(J_i) &= \begin{cases}
A_{p+1}^{\max} - 1 & \text{ if } p < s_i^{\max} \\
\infty & \text{ otherwise}
\end{cases}
\end{aligned}
$$

New eligibility condition:
$$
EST_i^p \le LST_i^p \land (p = s_i^{\max} \lor EST_i^p < A_{p+1}^{\max})
$$

New latest finishing time with $p$ cores:
$$
LFT_i^p = LST_i^p + c_i^{\max}(p)
$$

### Proofs

#### We want to prove $t_h^p(J_i, J_j)$ is correct

$$
t_h^p =
\begin{cases}
r_j^{\max} & \text{ if } s_j^{\min} \le p \\
\max\{r_j^{\max}, A_{s_j^{\min}}^{\max}\} & \text{ otherwise}
\end{cases}
$$

We prove every branch independently

- First branch:
  - Assumptions: $s_j^{\min} \le p$,  $s_i^{\min} \le p \le s_i^{max}$ and $J_j \in \{hp_i \cap \mathcal{R}^v \}$
  - Claim: $r_j^{\max} \le t$
  - By contradiction, assume that $J_i$ starts executing before $J_j$
  - Let $t$ be the time at which $J_i$ starts executing. At least $s_i^{\min} \le p$ cores are available at time $t$ to execute $J_i$. At least $s_j^{\min} \le p$ cores are available to execute $J_j$.
  - Since $r_j^{\max} \le t$, by the (Job-Level Fixed Priority) JLFP scheduling policy, $J_j$ is chosen first by the scheduler to be dispatched at time $t$.
  - This contradicts the claim that $J_i$ starts executing before $J_j$. Either $r_j^{\max} > t$, $s_j^{\min} > p$ or $s_i^{\min} > p$
- Second branch:
  - Assumptions: $s_j^{\min} > p$, $s_i^{\min} \le p \le s_i^{\max}$ and $J_j \in \{hp_i \cap \mathcal{R}^v \}$
  - Claim: $\max\{r_j^{\max}, A_{s_j^{\min}}^{\max}\} \le t$
  - By contradiction, assume that $J_i$ starts executing before $J_j$.
  - Let $t$ be the time at which $J_i$ starts executing. At least $s_j^{\min}$ cores are available to execute $J_j$ since $A_{s_i^{\min}}^{\max} \le t$ 
  - Since $r_j^{\max} \le t$ by the JLFP scheduling policy, $J_j$ is chosen first by the scheduler to be dispatched at time $t$
  - This contradicts the assumption that $J_i$ starts executing before $J_j$. Either $\max\{r_j^{\max}, A_{s_j^{\min}}^{\max}\} > t$ or $s_j^{\min} \le p$

### We want to prove $t_{available}^p(J_i)$ is correct

$$
t_{available}^p(J_i) = 
\begin{cases}
A_{p+1}^{\max} - 1 & \text{ if } p < s_i^{\max} \\
\infty & \text{ otherwise}
\end{cases}
$$

- First branch ($t_{available}^p(J_i) = A_{p+1}^{\max} - 1 \text{ if } p < s_i^{\max}$):
  - Assumptions: $s_i^{\min} \le p < s_i^{\max}$ (we use discrete time)
  - Claim: $A^{\max}_{p+1} - 1 < t \implies A_{p+1}^{\max} \le t$
  - By contradiction, assume that $J_i$ starts executing with $p$ cores
  - Let $t$ be the time at which $J_i$ starts executing. At least $p + 1$ cores are available since $A_{p+1}^{\max} \le t$
  - Since $p+1$ cores are available, by the JLFP scheduling policy the job is scheduled with $p+1$ cores.
  - This contradicts the assumption that $J_i$ starts executing with $p$ cores. Either $A_{p+1}^{\max} > t$ or $p = s_i^{\max}$

## Review of papers

| Year | Name                                                         | Assumptions                                                  |  Same<br>problem   | Related<br>problem |   Same<br>method   | Related<br>method  | Observations                                             |
| :--: | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------: | :----------------: | :----------------: | :----------------: | :------------------------------------------------------- |
| 1998 | Elastic Task Model For Adaptive Rate Control                 | Periodic<br>EDF<br>$\tau_i\triangleq(C_i,T_{i_0},T_i^{\min},T_i^{\max},E_i)$ |        :x:         |        :x:         | :heavy_check_mark: |        :x:         | First introduction of elastic scheduling                 |
| 2002 | Adaptive Workload Management through Elastic Scheduling      | Periodic<br>EDF<br>$\tau_i\triangleq(C_i^{ub},T_{i_0},T_i^{\max},E_i)$ |        :x:         |        :x:         | :heavy_check_mark: |        :x:         | Load estimated by monitoring computation time            |
| 2009 | Generalized Elastic Scheduling for Real-Time Tasks           | Periodic<br>EDF<br> Deadline $\le$ Next release<br>$\tau_i \triangleq (C_i,T_i, T_i^{\min}, T_i^{\max}, E_i)$ |        :x:         |        :x:         | :heavy_check_mark: |        :x:         | Deadlines are not the next release but can be before     |
| 2019 | Elastic Scheduling for Parallel Real-Time Systems            | Periodic<br>$\tau_i \triangleq (C_i, L_i, U_i^{\min}, U_i^{\max}, E_i)$ |        :x:         |        :x:         |        :x:         | :heavy_check_mark: | Federated scheduling                                     |
| 2009 | Gang EDF scheduling of parallel task systems                 |                                                              | :heavy_check_mark: |        :x:         |        :x:         |        :x:         |                                                          |
| 2010 | Gang FTP scheduling of periodic and parallel rigid real-time tasks |                                                              | :heavy_check_mark: |        :x:         |        :x:         |        :x:         | Multiple FTP definitions                                 |
| 2016 | Optimal Scheduling of Periodic Gang Tasks                    | Parallel<br>Preemptive<br>Periodic (and sporadic)<br> $J_ij \triangleq (r_{ij}, s_i, c_i, d_{ij})$ <br> $\tau_i \triangleq (s_i, C_i, T_i)$ | :heavy_check_mark: |        :x:         |        :x:         | :heavy_check_mark: | Non-sustainability example<br>It has lots of preemptions |
| 2019 | Analysis techniques for supporting hard real-time sporadic gang task systems | Parallel<br>Sporadic<br>$J_{ij} \triangleq(r_{ij},s_i,c_i,d_{ij})$<br>$\tau_i\triangleq(s_i,C_i,T_i,D_i)$ | :heavy_check_mark: |        :x:         |        :x:         |        :x:         | Global EDF on multiprocessor<br>Utilization based test   |

## Proposed elastic scheduling

- We want to make the number of assigned cores elastic
- This scheduler is **non-work conserving**
- When assigning the cores we want to avoid having the CPU idle
- Thus we check all the possible number of tasks added and we choose the solution with the fewest idle seconds as possible, this is $O(n)$
- We trust that there's an algorithm that does a proper partition of the number of cores

