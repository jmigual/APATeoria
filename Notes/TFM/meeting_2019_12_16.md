# Meeting 2019-12-16

## New formulation

### Simple formulation

Only change the Latest Start Time ($LST_i$) in order to have the number of required cores ($LST_I^p$)
$$
\begin{aligned}
LST_i^p &= \min\{t_{wc}, t_{high}^p(J_i) - 1\} \\
t_{wc} &= \min_{J_j \in \mathcal{R}^v}\{\max\{R_j^{\max}, A_{s_j^{\min}}^{\max}\}\} \\
t_{high}^p(J_i) &= \min_{J_j \in \{hp_i\cap \mathcal{R}^v\}}^{\infty}\Big\{\max\Big\{t_{h}^p(J_i, J_j), 
\max_0 \{LFT^*_y(v) | J_y \in \mathcal{P}(J_j) \setminus \mathcal{P}(J_i)\}\Big\}\Big\} \\
t_{h}^p(J_i, J_j) &= \begin{cases}
r_j^{\max} & \text{ if } s_j^{\min} \le p \\
\max\{r_j^{\max}, A_{s_j^{\min}}^{\max}\} & \text{ otherwise}
\end{cases}
\end{aligned}
$$


### Advanced one

Change the Latest Start Time ($LST_i$) in order to have the number of required cores ($LST_i^p$)
$$
\begin{aligned}
LST_i^p &= \min\{t_{wc}, t_{high}^p(J_i) - 1, t^p_{available}(J_i)\} \\
t_{wc} &= \min_{J_j \in \mathcal{R}^v}\{\max\{R_j^{\max}, A_{s_j^{\min}}^{\max}\}\} \\
t_{high}^p(J_i) &= \min_{J_j \in \{hp_i\cap \mathcal{R}^v\}}^{\infty}\Big\{\max\Big\{t_{h}^p(J_i, J_j),
\max_0 \{LFT^*_y(v) | J_y \in \mathcal{P}(J_j) \setminus \mathcal{P}(J_i)\}\Big\}\Big\} \\
t_{h}^p(J_i, J_j) &= \begin{cases}
r_j^{\max} & \text{ if } s_j^{\min} \le p \\
\max\{r_j^{\max}, A_{s_j^{\min}}^{\max}\} & \text{ otherwise}
\end{cases} \\
t_{available}^p(J_i) &= \begin{cases}
A_{p+1}^{\max} - 1 & \text{ if } p < s_i^{\max} \\
\infty & \text{ otherwise}
\end{cases}
\end{aligned}
$$

New eligibility condition:
$$
EST_i^p \le LST_i^p \land (p = s_i^{\max} \lor EST_i^p < A_{p+1}^{\max})
$$

New latest finishing time with $p$ cores:
$$
LFT_i^p = LST_i^p + c_i^{\max}(p)
$$

### Proofs

#### We want to prove $t_h^p(J_i, J_j)$ is correct

$$
t_h^p =
\begin{cases}
r_j^{\max} & \text{ if } s_j^{\min} \le p \\
\max\{r_j^{\max}, A_{s_j^{\min}}^{\max}\} & \text{ otherwise}
\end{cases}
$$

We prove every branch independently

- First branch:
  - Assumptions: $s_j^{\min} \le p$,  $s_i^{\min} \le p \le s_i^{max}$ and $J_j \in \{hp_i \cap \mathcal{R}^v \}$
  - Claim: $r_j^{\max} \le t$
  - By contradiction, assume that $J_i$ starts executing before $J_j$
  - Let $t$ be the time at which $J_i$ starts executing. At least $s_i^{\min} \le p$ cores are available at time $t$ to execute $J_i$. At least $s_j^{\min} \le p$ cores are available to execute $J_j$.
  - Since $r_j^{\max} \le t$, by the (Job-Level Fixed Priority) JLFP scheduling policy, $J_j$ is chosen first by the scheduler to be dispatched at time $t$.
  - This contradicts the claim that $J_i$ starts executing before $J_j$. Either $r_j^{\max} > t$, $s_j^{\min} > p$ or $s_i^{\min} > p$
- Second branch:
  - Assumptions: $s_j^{\min} > p$, $s_i^{\min} \le p \le s_i^{\max}$ and $J_j \in \{hp_i \cap \mathcal{R}^v \}$
  - Claim: $\max\{r_j^{\max}, A_{s_j^{\min}}^{\max}\} \le t$
  - By contradiction, assume that $J_i$ starts executing before $J_j$.
  - Let $t$ be the time at which $J_i$ starts executing. At least $s_j^{\min}$ cores are available to execute $J_j$ since $A_{s_i^{\min}}^{\max} \le t$ 
  - Since $r_j^{\max} \le t$ by the JLFP scheduling policy, $J_j$ is chosen first by the scheduler to be dispatched at time $t$
  - This contradicts the assumption that $J_i$ starts executing before $J_j$. Either $\max\{r_j^{\max}, A_{s_j^{\min}}^{\max}\} > t$ or $s_j^{\min} \le p$

### We want to prove $t_{available}^p(J_i)$ is correct

$$
t_{available}^p(J_i) = 
\begin{cases}
A_{p+1}^{\max} - 1 & \text{ if } p < s_i^{\max} \\
\infty & \text{ otherwise}
\end{cases}
$$

- First branch ($t_{available}^p(J_i) = A_{p+1}^{\max} - 1 \text{ if } p < s_i^{\max}$):
  - Assumptions: $s_i^{\min} \le p < s_i^{\max}$ (we use discrete time)
  - Claim: $A^{\max}_{p+1} - 1 < t \implies A_{p+1}^{\max} \le t$
  - By contradiction, assume that $J_i$ starts executing with $p$ cores
  - Let $t$ be the time at which $J_i$ starts executing. At least $p + 1$ cores are available since $A_{p+1}^{\max} \le t$
  - Since $p+1$ cores are available, by the JLFP scheduling policy the job is scheduled with $p+1$ cores.
  - This contradicts the assumption that $J_i$ starts executing with $p$ cores. Either $A_{p+1}^{\max} > t$ or $p = s_i^{\max}$

## Review of papers

### Elastic

| Year | Name                                                         | Assumptions                                                  |      Problem      |       Method       | Observations                                                |
| :--: | :----------------------------------------------------------- | :----------------------------------------------------------- | :---------------: | :----------------: | :---------------------------------------------------------- |
| 1998 | Elastic Task Model For<br>Adaptive Rate Control              | Single-core<br>Periodic<br>EDF<br>$\tau_i\triangleq(C_i,T_{i_0},T_i^{\min},T_i^{\max},E_i)$ |        :x:        | :heavy_check_mark: | First introduction of elastic scheduling                    |
| 2002 | Adaptive Workload Management<br>through Elastic Scheduling   | Single-core<br>Periodic<br>EDF<br>$\tau_i\triangleq(C_i^{ub},T_{i_0},T_i^{\max},E_i)$ |        :x:        | :heavy_check_mark: | Load estimated by monitoring computation time               |
| 2009 | Generalized Elastic Scheduling<br>for Real-Time Tasks        | Single-core<br>Periodic<br>EDF<br>Deadline $\le$ Next release<br>$\tau_i \triangleq (C_i,T_i, T_i^{\min}, T_i^{\max}, E_i)$ |        :x:        | :heavy_check_mark: | Deadlines are not the next release but can be before        |
| 2018 | Elasticity of workloads and<br>periods of parallel real-time tasks | Multicore<br>Computational elasticity<br>Federated scheduling<br>$\tau_i\triangleq(T_i,L_i,U_i^{\max},U_i^{\min},E_i)$ | :heavy_plus_sign: | :heavy_check_mark: | Federated scheduling<br>Each task at least uses 1 processor |
| 2019 | Elastic Scheduling for<br>Parallel Real-Time Systems         | Multicore<br>Periodic<br>$\tau_i \triangleq (C_i, L_i, U_i^{\min}, U_i^{\max}, E_i)$ |        :x:        | :heavy_plus_sign:  | Federated scheduling                                        |


### Gang

| **Year** | **Name** | **Assumptions** | **Problem** | **Method** | **Observations** |
| -------- | -------- | --------------- | ----------- | ---------- | ---------------- |
| 2008 | Integrating job parallelism in<br>real-time scheduling theory | EDF<br>Sporadic<br>Multicore<br>Preemptive<br>$\tau_i \triangleq(s_i, C_i, D_i, T_i)$ | :heavy_plus_sign:  |        :x:         | Basic notions of job parallelism                         |
| 2009 | Gang EDF scheduling of<br>parallel task systems             | Preemptive<br>Multicore<br>Periodic<br>Moldable<br>EDF<br>$\tau_i \triangleq (s_i, C_i, D_i, T_i)$ | :heavy_check_mark: |        :x:         | Gang EDF schedulability condition                        |
| 2010 | Gang FTP scheduling of periodic and<br>parallel rigid real-time tasks | Multicore<br>Preemptive<br>Fixed Task Priority<br>Periodic<br>$\tau_i\triangleq(O_i,s_i,C_i,D_i,T_i)$ | :heavy_check_mark: |        :x:         | Multiple FTP definitions                                 |
| 2016 | Optimal Scheduling of<br>Periodic Gang Tasks                | Multicore<br>Preemptive<br>Periodic (and sporadic)<br> $J_ij \triangleq (r_{ij}, s_i, c_i, d_{ij})$ <br> $\tau_i \triangleq (s_i, C_i, T_i)$ | :heavy_check_mark: | :heavy_plus_sign:  | Non-sustainability example<br>It has lots of preemptions |
| 2019 | Analysis techniques for supporting hard<br>real-time sporadic gang task systems | Multicore<br>Preemptive<br>Global EDF<br>Sporadic<br>$J_{ij} \triangleq(r_{ij},s_i,c_i,d_{ij})$<br>$\tau_i\triangleq(s_i,C_i,T_i,D_i)$ | :heavy_check_mark: |        :x:         | Global EDF on multiprocessor<br>Utilization based test   |



### Schedule Abstraction Graph

| **Year** | **Name**                                                     | **Assumptions**                                     | **Problem** | **Method** | **Observations**                                             |
| ---- | ---- | ---- | ---- | ---- | ---- |
| 2018 | An Exact and Sustainable Analysis<br>of Non-Preemptive Scheduling | Non-Preemptive<br>Single-core<br>Fixed-Job Priority<br>$J_i\triangleq([r_i^{\min},r_i^{\max}],[C_i^{\min},C_i^{\max}],d_i,p_i)$ | :x: | :heavy_plus_sign: | Scalability Analysis definition<br>of Non-Preemptive |
| 2018 | A Response-Time Analysis for Non-Preemptive<br>Job Sets under Global Scheduling | Non-Preemptive<br>Global Job-Level Fixed Priority<br>Multicore<br>Sporadic<br>$J_i\triangleq([r_i^{\min},r_i^{\max}],[C_i^{\min},C_i^{\max}],d_i,p_i)$ | :x: | :heavy_plus_sign: | Scalability Analysis on<br>multicore platforms |
| 2019 | Response-Time Analysis of Limited-Preemptive<br>Parallel DAG Tasks Under Global Scheduling | Non-Preemptive<br>Global Job-Level Fixed-Priority<br>Multicore<br>Sporadic DAG<br>$J_i\triangleq([r_i^{\min},r_i^{\max}],[C_i^{\min},C_i^{\max}],d_i,p_i, pred_i)$ |  |  |  |



### Discarded

| **Year** | **Name**                                                     | **Assumptions**                                     | **Problem** | **Method** | **Observations**                                             |
| -------- | ------------------------------------------------------------ | --------------------------------------------------- | ----------- | ---------- | ------------------------------------------------------------ |
| 2019     | Analyzing Parallel Real-Time<br>Tasks Implemented with Thread Pools | Parallel<br>$\tau_i\triangleq(G_i,D_i,T_i,s_i,p_i)$ | :x:         | :x:        | It is based in parallel DAG tasks.<br>Maybe could be modeled as gang?<br>**Related but not useful** |
| 2019     | Adaptive workload management in<br>mixed-criticality systems |                                                     | :x:         | :x:        | One of the author's name is gang<br>**Not related**          |

## Proposed elastic scheduling

- We want to make the number of assigned cores elastic

We can have two objectives when proposing the elastic scheduling

### Real elastic scheduling

This will extend the work from Buttazzo et al (1998). Problems by implementing it in gang scheduling:

- Tasks cannot use a fraction of a core so we have to decide how to assign them
- We have to decide whether to add or remove tasks if multiple are available

### Least slack scheduling

- We want to minimize the slack of the released tasks
- Multiple tasks can be released at once
- Try all the options and use the one with less slack
- It can be **non-work-conserving**

